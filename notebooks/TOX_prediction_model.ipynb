{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afdafb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from typing import Union\n",
    "\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from Simple_Model.features import smiles_to_graph\n",
    "from Simple_Model.models.gnn import GNNModel\n",
    "from Simple_Model.models.message_passing import MPNN\n",
    "from Simple_Model.models.hgnn import HGNNModel\n",
    "from Simple_Model.models.ginn import GINModel\n",
    "from Simple_Model.models.gat import GATModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee6fcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCGC00260230-01</td>\n",
       "      <td>F[P-](F)(F)(F)(F)F.CCCC[N+]1=CC=CC(C)=C1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCGC00184995-01</td>\n",
       "      <td>[H][C@@]12CC[C@H](OP(O)(O)=O)[C@@]1(C)CC[C@]3(...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCGC00260471-01</td>\n",
       "      <td>[O-][N+](=O)C1=CC=C2NN=CC2=C1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCGC00256746-01</td>\n",
       "      <td>CCC1=NC=CN=C1C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCGC00183024-01</td>\n",
       "      <td>CCCN(CCC)C(=O)C(CCC(=O)OCCCN1CCN(CCOC(=O)CC2=C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs                                             SMILES  Labels\n",
       "0  NCGC00260230-01           F[P-](F)(F)(F)(F)F.CCCC[N+]1=CC=CC(C)=C1       0\n",
       "1  NCGC00184995-01  [H][C@@]12CC[C@H](OP(O)(O)=O)[C@@]1(C)CC[C@]3(...       1\n",
       "2  NCGC00260471-01                      [O-][N+](=O)C1=CC=C2NN=CC2=C1       0\n",
       "3  NCGC00256746-01                                     CCC1=NC=CN=C1C       0\n",
       "4  NCGC00183024-01  CCCN(CCC)C(=O)C(CCC(=O)OCCCN1CCN(CCOC(=O)CC2=C...       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_path = \"D:/PropPredictionModel/PropPredictionModel/tests/toxicity/data\"\n",
    "os.listdir(data_path)\n",
    "train_df_Smiles = pd.read_csv(data_path+'/NR-ER-train/names_smiles.csv')#,header = True)\n",
    "train_df_Labels = pd.read_csv(data_path+'/NR-ER-train/names_labels.csv')#,header = True)\n",
    "train_df = pd.merge(train_df_Smiles, train_df_Labels, on='IDs')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4257889",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(data_path+'/train_tox_data.csv')\n",
    "test_df.to_csv(data_path+'/test_tox_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c9f372f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCGC00261443-01</td>\n",
       "      <td>CNC1=C2N=CN([C@@H]3O[C@H](CO)C(O)[C@H]3O)C2=NC=N1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCGC00261600-01</td>\n",
       "      <td>OC1=CC(\\C=C\\C2=CC=C(O)C(O)=C2)=CC(O)=C1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCGC00260926-01</td>\n",
       "      <td>[Cl-].COC1=CC=C2C3=CC=C4C=C5OCOC5=CC4=C3[N+](C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCGC00261266-01</td>\n",
       "      <td>Br.CC1=C(CC(N)C(O)=O)C(O)=NO1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCGC00261559-01</td>\n",
       "      <td>C1C(CC2=C1C=CC=C2)N3CCN(CC3)C4=CC=CC5=C4OCCO5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               IDs                                             SMILES  Labels\n",
       "0  NCGC00261443-01  CNC1=C2N=CN([C@@H]3O[C@H](CO)C(O)[C@H]3O)C2=NC=N1       0\n",
       "1  NCGC00261600-01            OC1=CC(\\C=C\\C2=CC=C(O)C(O)=C2)=CC(O)=C1       1\n",
       "2  NCGC00260926-01  [Cl-].COC1=CC=C2C3=CC=C4C=C5OCOC5=CC4=C3[N+](C...       0\n",
       "3  NCGC00261266-01                      Br.CC1=C(CC(N)C(O)=O)C(O)=NO1       0\n",
       "4  NCGC00261559-01      C1C(CC2=C1C=CC=C2)N3CCN(CC3)C4=CC=CC5=C4OCCO5       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_Smiles = pd.read_csv(data_path+'/NR-ER-test/names_smiles.csv')#,header = True)\n",
    "test_df_Labels = pd.read_csv(data_path+'/NR-ER-test/names_labels.csv')#,header = True)\n",
    "test_df = pd.merge(test_df_Smiles, test_df_Labels, on='IDs')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdcb47ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7697, 265)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df),len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab398d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:17:07] Explicit valence for atom # 2 Cl, 2, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES: [NH4+].[NH4+].[Cl-][Pt++]([Cl-])([Cl-])[Cl-]. Error: Invalid SMILES string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:17:07] Explicit valence for atom # 3 Si, 8, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES: [Na+].[Na+].F[Si--](F)(F)(F)(F)F. Error: Invalid SMILES string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:17:08] Explicit valence for atom # 0 Cl, 2, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing SMILES: [Cl-][Pt]1([Cl-])NCCN1. Error: Invalid SMILES string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[00:17:08] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "graphs = []\n",
    "for smiles, label in zip(train_df[\"SMILES\"], train_df[\"Labels\"]):\n",
    "    try:\n",
    "        # Convert SMILES to graph\n",
    "        graph = smiles_to_graph(smiles)\n",
    "        \n",
    "        # Add the label as a tensor\n",
    "        graph.y = torch.tensor([label], dtype=torch.float)  # Use torch.float for regression, torch.long for classification\n",
    "        \n",
    "        graphs.append(graph)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing SMILES: {smiles}. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d263123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[1040, 1], edge_index=[2, 2110], edge_attr=[2110, 3], y=[64], batch=[1040], ptr=[65])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\anaconda3\\envs\\py310_env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Use a DataLoader for batching\n",
    "loader = DataLoader(graphs, batch_size=64, shuffle=True)\n",
    "loader_iter = iter(loader)\n",
    "\n",
    "# Get the next batch\n",
    "batch = next(loader_iter)\n",
    "\n",
    "# Print the batch\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19ee5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel(\n",
      "  (node_embedding): Linear(in_features=1, out_features=64, bias=True)\n",
      "  (conv1): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (conv2): GINEConv(nn=Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  ))\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 1, Avg Loss per Batch: 0.3864, Accuracy: 0.8782\n",
      "Epoch 2, Avg Loss per Batch: 0.3735, Accuracy: 0.8782\n",
      "Epoch 3, Avg Loss per Batch: 0.3655, Accuracy: 0.8782\n",
      "Epoch 4, Avg Loss per Batch: 0.3624, Accuracy: 0.8782\n",
      "Epoch 5, Avg Loss per Batch: 0.3634, Accuracy: 0.8782\n",
      "Epoch 6, Avg Loss per Batch: 0.3573, Accuracy: 0.8782\n",
      "Epoch 7, Avg Loss per Batch: 0.3559, Accuracy: 0.8782\n",
      "Epoch 8, Avg Loss per Batch: 0.3569, Accuracy: 0.8782\n",
      "Epoch 9, Avg Loss per Batch: 0.3582, Accuracy: 0.8782\n",
      "Epoch 10, Avg Loss per Batch: 0.3557, Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "# Define model and optimizer\n",
    "model = GNNModel(in_node_features=1, in_edge_features=3, \n",
    "                 hidden_dim=64, num_classes=1)  # Regression or binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(model)\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch)  # Forward pass\n",
    "        target = batch.y.view(-1, 1).float()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        correct += (preds == target).sum().item()\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_loss_per_batch = total_loss / len(loader)  # Average loss per batch\n",
    "    avg_loss_per_sample = total_loss / len(loader.dataset)  # Average loss per sample\n",
    "    accuracy = correct / len(loader.dataset)  # Accuracy\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch + 1}, Avg Loss per Batch: {avg_loss_per_batch:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3c699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss per Batch: 0.3940, Accuracy: 0.8707\n",
      "Epoch 2, Avg Loss per Batch: 0.3786, Accuracy: 0.8770\n",
      "Epoch 3, Avg Loss per Batch: 0.3755, Accuracy: 0.8770\n",
      "Epoch 4, Avg Loss per Batch: 0.3703, Accuracy: 0.8778\n",
      "Epoch 5, Avg Loss per Batch: 0.3676, Accuracy: 0.8782\n",
      "Epoch 6, Avg Loss per Batch: 0.3709, Accuracy: 0.8782\n",
      "Epoch 7, Avg Loss per Batch: 0.3692, Accuracy: 0.8782\n",
      "Epoch 8, Avg Loss per Batch: 0.3685, Accuracy: 0.8782\n",
      "Epoch 9, Avg Loss per Batch: 0.3656, Accuracy: 0.8782\n",
      "Epoch 10, Avg Loss per Batch: 0.3639, Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "# Define model and optimizer\n",
    "model = MPNN(in_node_features=1, in_edge_features=3, hidden_dim=64, num_classes=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    correct = 0  # Reset correct predictions for each epoch\n",
    "\n",
    "    for batch in loader:  # Assuming 'loader' is your DataLoader\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch)  # Forward pass\n",
    "        target = batch.y.view(-1, 1).float()  # Reshape target for BCEWithLogitsLoss\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Accuracy\n",
    "        preds = torch.round(torch.sigmoid(logits))  # Convert logits to probabilities, then round\n",
    "        correct += (preds == target).sum().item()  # Accumulate correct predictions\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_loss_per_batch = total_loss / len(loader)  # Average loss per batch\n",
    "    avg_loss_per_sample = total_loss / len(loader.dataset)  # Average loss per sample\n",
    "    accuracy = correct / len(loader.dataset)  # Accuracy (normalize by dataset size)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch + 1}, Avg Loss per Batch: {avg_loss_per_batch:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c31a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.3973, Accuracy: 0.8782\n",
      "Epoch 2, Avg Loss: 0.3697, Accuracy: 0.8782\n",
      "Epoch 3, Avg Loss: 0.3698, Accuracy: 0.8782\n",
      "Epoch 4, Avg Loss: 0.3707, Accuracy: 0.8782\n",
      "Epoch 5, Avg Loss: 0.3715, Accuracy: 0.8782\n",
      "Epoch 6, Avg Loss: 0.3692, Accuracy: 0.8782\n",
      "Epoch 7, Avg Loss: 0.3693, Accuracy: 0.8782\n",
      "Epoch 8, Avg Loss: 0.3695, Accuracy: 0.8782\n",
      "Epoch 9, Avg Loss: 0.3697, Accuracy: 0.8782\n",
      "Epoch 10, Avg Loss: 0.3676, Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "model = HGNNModel(in_node_features=1, hidden_dim=64, num_classes=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch)\n",
    "        target = batch.y.view(-1, 1).float()\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        correct += (preds == target).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}, Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16c4ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.3828, Accuracy: 0.8782\n",
      "Epoch 2, Avg Loss: 0.3863, Accuracy: 0.8782\n",
      "Epoch 3, Avg Loss: 0.3848, Accuracy: 0.8782\n",
      "Epoch 4, Avg Loss: 0.3836, Accuracy: 0.8782\n",
      "Epoch 5, Avg Loss: 0.3821, Accuracy: 0.8782\n",
      "Epoch 6, Avg Loss: 0.3776, Accuracy: 0.8782\n",
      "Epoch 7, Avg Loss: 0.3786, Accuracy: 0.8782\n",
      "Epoch 8, Avg Loss: 0.3797, Accuracy: 0.8782\n",
      "Epoch 9, Avg Loss: 0.3768, Accuracy: 0.8782\n",
      "Epoch 10, Avg Loss: 0.3775, Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "#GINModel\n",
    "model = GINModel(in_node_features=1, hidden_dim=64, num_classes=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch)\n",
    "        target = batch.y.view(-1, 1).float()\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        correct += (preds == target).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}, Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6854bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 0.3747, Accuracy: 0.8782\n",
      "Epoch 2, Avg Loss: 0.3664, Accuracy: 0.8782\n",
      "Epoch 3, Avg Loss: 0.3674, Accuracy: 0.8782\n",
      "Epoch 4, Avg Loss: 0.3688, Accuracy: 0.8782\n",
      "Epoch 5, Avg Loss: 0.3692, Accuracy: 0.8782\n",
      "Epoch 6, Avg Loss: 0.3676, Accuracy: 0.8782\n",
      "Epoch 7, Avg Loss: 0.3678, Accuracy: 0.8782\n",
      "Epoch 8, Avg Loss: 0.3680, Accuracy: 0.8782\n",
      "Epoch 9, Avg Loss: 0.3697, Accuracy: 0.8782\n",
      "Epoch 10, Avg Loss: 0.3666, Accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "#GATModel\n",
    "model = GATModel(in_node_features=1, hidden_dim=64, num_classes=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch)\n",
    "        target = batch.y.view(-1, 1).float()\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        correct += (preds == target).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    print(f\"Epoch {epoch + 1}, Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec485b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310_env)",
   "language": "python",
   "name": "py310_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
